{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지정된 폴더 내의 모든 JSON 파일을 찾습니다.  \n",
    "각 JSON 파일에 대한 이미지 파일 이름과 텍스트 레이블을 추출합니다.  \n",
    "추출된 정보를 gt.txt 파일에 쓰기합니다.  \n",
    "이 스크립트를 사용하려면, your_dataset_folder를 실제 데이터셋이 위치한 폴더 경로로 변경해야 합니다.  \n",
    "이 스크립트는 지정된 폴더 내의 모든 JSON 파일을 처리하고, 각 파일에 대응하는 이미지 파일 이름과 텍스트 레이블을 gt.txt 파일에 기록합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 필기체 글자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# The root folder where the dataset folders (001, 002, ...) are located\n",
    "root_dataset_folder = \"C:/workspace_project/korean_characters/Training/[라벨]Training_필기체/1.글자\"\n",
    "\n",
    "# Define the function to process each json file\n",
    "def process_json_file(json_path):\n",
    "    # Open the json file and load its content\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    # Get the relative path of the json file from the root_dataset_folder\n",
    "    relative_path = os.path.relpath(os.path.dirname(json_path), root_dataset_folder)\n",
    "\n",
    "    # Try to extract the image file name\n",
    "    try:\n",
    "        image_file_name = json_data[\"image\"][\"file_name\"]\n",
    "    except KeyError:\n",
    "        print(f\"'file_name' key not found in {json_path}\")\n",
    "        return None\n",
    "\n",
    "    full_image_path = os.path.join(relative_path, image_file_name)\n",
    "    \n",
    "# Try to extract the text label, handle KeyError if the structure is not as expected\n",
    "    try:\n",
    "        text_letter = json_data[\"text\"][\"letter\"]\n",
    "        text_label = text_letter[\"value\"]\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} not found in {json_path}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "    # Return the formatted string with a tab separator\n",
    "    return f\"{full_image_path}\\t{text_label}\\n\"\n",
    "\n",
    "# Create a list to hold all the paths to json files\n",
    "json_files = []\n",
    "# Walk through the directory tree starting from the root dataset folder\n",
    "for subdir, dirs, files in os.walk(root_dataset_folder):\n",
    "    for file in files:\n",
    "        # Check if the file is a json file\n",
    "        if file.endswith(\".json\"):\n",
    "            # Construct the full file path and add it to the list\n",
    "            json_files.append(os.path.join(subdir, file))\n",
    "\n",
    "# Prepare to write the output to the gt.txt file\n",
    "# Open the file outside of the loop to avoid opening and closing it multiple times\n",
    "gt_file_path = os.path.join(root_dataset_folder, \"gt.txt\")\n",
    "with open(gt_file_path, \"w\", encoding=\"utf-8\") as gt_file:\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in executor.map(process_json_file, json_files):\n",
    "            if result:  # Only write results that are not None\n",
    "                gt_file.write(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation 필기체 글자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# The root folder where the dataset folders (001, 002, ...) are located\n",
    "root_dataset_folder = \"C:/workspace_project/korean_characters/validation/[라벨]validation_필기체/1.글자\"\n",
    "\n",
    "# Define the function to process each json file\n",
    "def process_json_file(json_path):\n",
    "    # Open the json file and load its content\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    # Get the relative path of the json file from the root_dataset_folder\n",
    "    relative_path = os.path.relpath(os.path.dirname(json_path), root_dataset_folder)\n",
    "\n",
    "    # Try to extract the image file name\n",
    "    try:\n",
    "        image_file_name = json_data[\"image\"][\"file_name\"]\n",
    "    except KeyError:\n",
    "        print(f\"'file_name' key not found in {json_path}\")\n",
    "        return None\n",
    "\n",
    "    full_image_path = os.path.join(relative_path, image_file_name)\n",
    "    \n",
    "# Try to extract the text label, handle KeyError if the structure is not as expected\n",
    "    try:\n",
    "        text_letter = json_data[\"text\"][\"letter\"]\n",
    "        text_label = text_letter[\"value\"]\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} not found in {json_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Return the formatted string with a tab separator\n",
    "    return f\"{full_image_path}\\t{text_label}\\n\"\n",
    "\n",
    "# Create a list to hold all the paths to json files\n",
    "json_files = []\n",
    "# Walk through the directory tree starting from the root dataset folder\n",
    "for subdir, dirs, files in os.walk(root_dataset_folder):\n",
    "    for file in files:\n",
    "        # Check if the file is a json file\n",
    "        if file.endswith(\".json\"):\n",
    "            # Construct the full file path and add it to the list\n",
    "            json_files.append(os.path.join(subdir, file))\n",
    "\n",
    "# Prepare to write the output to the gt.txt file\n",
    "# Open the file outside of the loop to avoid opening and closing it multiple times\n",
    "gt_file_path = os.path.join(root_dataset_folder, \"gt.txt\")\n",
    "with open(gt_file_path, \"w\", encoding=\"utf-8\") as gt_file:\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in executor.map(process_json_file, json_files):\n",
    "            if result:  # Only write results that are not None\n",
    "                gt_file.write(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 필기체 글자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# The root folder where the dataset folders (001, 002, ...) are located\n",
    "root_dataset_folder = \"C:/workspace_project/korean_characters/test/[라벨]test_필기체/1.글자\"\n",
    "\n",
    "# Define the function to process each json file\n",
    "def process_json_file(json_path):\n",
    "    # Open the json file and load its content\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    # Get the relative path of the json file from the root_dataset_folder\n",
    "    relative_path = os.path.relpath(os.path.dirname(json_path), root_dataset_folder)\n",
    "\n",
    "    # Try to extract the image file name\n",
    "    try:\n",
    "        image_file_name = json_data[\"image\"][\"file_name\"]\n",
    "    except KeyError:\n",
    "        print(f\"'file_name' key not found in {json_path}\")\n",
    "        return None\n",
    "\n",
    "    full_image_path = os.path.join(relative_path, image_file_name)\n",
    "    \n",
    "    # Try to extract the text label, handle KeyError if the structure is not as expected\n",
    "    try:\n",
    "        text_letter = json_data[\"text\"][\"letter\"]\n",
    "        text_label = text_letter[\"value\"]\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} not found in {json_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Return the formatted string with a tab separator\n",
    "    return f\"{full_image_path}\\t{text_label}\\n\"\n",
    "\n",
    "# Create a list to hold all the paths to json files\n",
    "json_files = []\n",
    "# Walk through the directory tree starting from the root dataset folder\n",
    "for subdir, dirs, files in os.walk(root_dataset_folder):\n",
    "    for file in files:\n",
    "        # Check if the file is a json file\n",
    "        if file.endswith(\".json\"):\n",
    "            # Construct the full file path and add it to the list\n",
    "            json_files.append(os.path.join(subdir, file))\n",
    "\n",
    "# Prepare to write the output to the gt.txt file\n",
    "# Open the file outside of the loop to avoid opening and closing it multiple times\n",
    "gt_file_path = os.path.join(root_dataset_folder, \"gt.txt\")\n",
    "with open(gt_file_path, \"w\", encoding=\"utf-8\") as gt_file:\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in executor.map(process_json_file, json_files):\n",
    "            if result:  # Only write results that are not None\n",
    "                gt_file.write(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# The root folder where the dataset folders (001, 002, ...) are located\n",
    "root_dataset_folder = \"C:/workspace_project/korean_characters/Training/[라벨]Training_필기체/1.글자\"\n",
    "\n",
    "# Define the function to process each json file\n",
    "def process_json_file(json_path):\n",
    "    # Open the json file and load its content\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    # Get the relative path of the json file from the root_dataset_folder\n",
    "    relative_path = os.path.relpath(os.path.dirname(json_path), root_dataset_folder)\n",
    "\n",
    "    # Try to extract the image file name\n",
    "    try:\n",
    "        image_file_name = json_data[\"image\"][\"file_name\"]\n",
    "    except KeyError:\n",
    "        print(f\"'file_name' key not found in {json_path}\")\n",
    "        return None\n",
    "\n",
    "    full_image_path = os.path.join(relative_path, image_file_name)\n",
    "    \n",
    "    # Try to extract the text label, handle KeyError if the structure is not as expected\n",
    "    try:\n",
    "        text_words = json_data[\"text\"][\"word\"]\n",
    "        text_label = ''.join(word[\"value\"] for word in text_words)\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} not found in {json_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Return the formatted string with a tab separator\n",
    "    return f\"{full_image_path}\\t{text_label}\\n\"\n",
    "\n",
    "# Create a list to hold all the paths to json files\n",
    "json_files = []\n",
    "# Walk through the directory tree starting from the root dataset folder\n",
    "for subdir, dirs, files in os.walk(root_dataset_folder):\n",
    "    for file in files:\n",
    "        # Check if the file is a json file\n",
    "        if file.endswith(\".json\"):\n",
    "            # Construct the full file path and add it to the list\n",
    "            json_files.append(os.path.join(subdir, file))\n",
    "\n",
    "# Prepare to write the output to the gt.txt file\n",
    "# Open the file outside of the loop to avoid opening and closing it multiple times\n",
    "gt_file_path = os.path.join(root_dataset_folder, \"gt.txt\")\n",
    "with open(gt_file_path, \"w\", encoding=\"utf-8\") as gt_file:\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in executor.map(process_json_file, json_files):\n",
    "            if result:  # Only write results that are not None\n",
    "                gt_file.write(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# The root folder where the dataset folders (001, 002, ...) are located\n",
    "root_dataset_folder = \"C:/workspace_project/korean_characters/validation/[라벨]validation_필기체/1.글자\"\n",
    "\n",
    "# Define the function to process each json file\n",
    "def process_json_file(json_path):\n",
    "    # Open the json file and load its content\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    # Get the relative path of the json file from the root_dataset_folder\n",
    "    relative_path = os.path.relpath(os.path.dirname(json_path), root_dataset_folder)\n",
    "\n",
    "    # Try to extract the image file name\n",
    "    try:\n",
    "        image_file_name = json_data[\"image\"][\"file_name\"]\n",
    "    except KeyError:\n",
    "        print(f\"'file_name' key not found in {json_path}\")\n",
    "        return None\n",
    "\n",
    "    full_image_path = os.path.join(relative_path, image_file_name)\n",
    "    \n",
    "    # Try to extract the text label, handle KeyError if the structure is not as expected\n",
    "    try:\n",
    "        text_words = json_data[\"text\"][\"word\"]\n",
    "        text_label = ''.join(word[\"value\"] for word in text_words)\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} not found in {json_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Return the formatted string with a tab separator\n",
    "    return f\"{full_image_path}\\t{text_label}\\n\"\n",
    "\n",
    "# Create a list to hold all the paths to json files\n",
    "json_files = []\n",
    "# Walk through the directory tree starting from the root dataset folder\n",
    "for subdir, dirs, files in os.walk(root_dataset_folder):\n",
    "    for file in files:\n",
    "        # Check if the file is a json file\n",
    "        if file.endswith(\".json\"):\n",
    "            # Construct the full file path and add it to the list\n",
    "            json_files.append(os.path.join(subdir, file))\n",
    "\n",
    "# Prepare to write the output to the gt.txt file\n",
    "# Open the file outside of the loop to avoid opening and closing it multiple times\n",
    "gt_file_path = os.path.join(root_dataset_folder, \"gt.txt\")\n",
    "with open(gt_file_path, \"w\", encoding=\"utf-8\") as gt_file:\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in executor.map(process_json_file, json_files):\n",
    "            if result:  # Only write results that are not None\n",
    "                gt_file.write(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# The root folder where the dataset folders (001, 002, ...) are located\n",
    "root_dataset_folder = \"C:/workspace_project/korean_characters/test/[라벨]test_필기체/1.글자\"\n",
    "\n",
    "# Define the function to process each json file\n",
    "def process_json_file(json_path):\n",
    "    # Open the json file and load its content\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    # Get the relative path of the json file from the root_dataset_folder\n",
    "    relative_path = os.path.relpath(os.path.dirname(json_path), root_dataset_folder)\n",
    "\n",
    "    # Try to extract the image file name\n",
    "    try:\n",
    "        image_file_name = json_data[\"image\"][\"file_name\"]\n",
    "    except KeyError:\n",
    "        print(f\"'file_name' key not found in {json_path}\")\n",
    "        return None\n",
    "\n",
    "    full_image_path = os.path.join(relative_path, image_file_name)\n",
    "    \n",
    "    # Try to extract the text label, handle KeyError if the structure is not as expected\n",
    "    try:\n",
    "        text_words = json_data[\"text\"][\"word\"]\n",
    "        text_label = ''.join(word[\"value\"] for word in text_words)\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} not found in {json_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Return the formatted string with a tab separator\n",
    "    return f\"{full_image_path}\\t{text_label}\\n\"\n",
    "\n",
    "# Create a list to hold all the paths to json files\n",
    "json_files = []\n",
    "# Walk through the directory tree starting from the root dataset folder\n",
    "for subdir, dirs, files in os.walk(root_dataset_folder):\n",
    "    for file in files:\n",
    "        # Check if the file is a json file\n",
    "        if file.endswith(\".json\"):\n",
    "            # Construct the full file path and add it to the list\n",
    "            json_files.append(os.path.join(subdir, file))\n",
    "\n",
    "# Prepare to write the output to the gt.txt file\n",
    "# Open the file outside of the loop to avoid opening and closing it multiple times\n",
    "gt_file_path = os.path.join(root_dataset_folder, \"gt.txt\")\n",
    "with open(gt_file_path, \"w\", encoding=\"utf-8\") as gt_file:\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in executor.map(process_json_file, json_files):\n",
    "            if result:  # Only write results that are not None\n",
    "                gt_file.write(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
